{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d848ef65da8b561d",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67887d1dd48e7f2",
   "metadata": {},
   "source": [
    "## Reading and Handling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b018cd3f9c342d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:56.166796Z",
     "start_time": "2025-04-06T14:19:56.020056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Loan Amount</th>\n",
       "      <th>Loan Purpose</th>\n",
       "      <th>Employment Status</th>\n",
       "      <th>Years at Current Job</th>\n",
       "      <th>Payment History</th>\n",
       "      <th>Debt-to-Income Ratio</th>\n",
       "      <th>Assets Value</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Previous Defaults</th>\n",
       "      <th>Marital Status Change</th>\n",
       "      <th>Risk Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>72799.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>45713.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>19</td>\n",
       "      <td>Poor</td>\n",
       "      <td>0.154313</td>\n",
       "      <td>120228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Port Elizabeth</td>\n",
       "      <td>AS</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690.0</td>\n",
       "      <td>33835.0</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Employed</td>\n",
       "      <td>6</td>\n",
       "      <td>Fair</td>\n",
       "      <td>0.148920</td>\n",
       "      <td>55849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North Catherine</td>\n",
       "      <td>OH</td>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Single</td>\n",
       "      <td>55687.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>36623.0</td>\n",
       "      <td>Home</td>\n",
       "      <td>Employed</td>\n",
       "      <td>8</td>\n",
       "      <td>Fair</td>\n",
       "      <td>0.362398</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>South Scott</td>\n",
       "      <td>OK</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Single</td>\n",
       "      <td>26508.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>26541.0</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>2</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0.454964</td>\n",
       "      <td>157319.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Robinhaven</td>\n",
       "      <td>PR</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>49427.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>36528.0</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>10</td>\n",
       "      <td>Fair</td>\n",
       "      <td>0.143242</td>\n",
       "      <td>287140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Heather</td>\n",
       "      <td>IL</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age      Gender Education Level Marital Status   Income  Credit Score  \\\n",
       "0   49        Male             PhD       Divorced  72799.0         688.0   \n",
       "1   57      Female      Bachelor's        Widowed      NaN         690.0   \n",
       "2   21  Non-binary        Master's         Single  55687.0         600.0   \n",
       "3   59        Male      Bachelor's         Single  26508.0         622.0   \n",
       "4   25  Non-binary      Bachelor's        Widowed  49427.0         766.0   \n",
       "\n",
       "   Loan Amount Loan Purpose Employment Status  Years at Current Job  \\\n",
       "0      45713.0     Business        Unemployed                    19   \n",
       "1      33835.0         Auto          Employed                     6   \n",
       "2      36623.0         Home          Employed                     8   \n",
       "3      26541.0     Personal        Unemployed                     2   \n",
       "4      36528.0     Personal        Unemployed                    10   \n",
       "\n",
       "  Payment History  Debt-to-Income Ratio  Assets Value  Number of Dependents  \\\n",
       "0            Poor              0.154313      120228.0                   0.0   \n",
       "1            Fair              0.148920       55849.0                   0.0   \n",
       "2            Fair              0.362398      180700.0                   3.0   \n",
       "3       Excellent              0.454964      157319.0                   3.0   \n",
       "4            Fair              0.143242      287140.0                   NaN   \n",
       "\n",
       "              City State       Country  Previous Defaults  \\\n",
       "0   Port Elizabeth    AS        Cyprus                2.0   \n",
       "1  North Catherine    OH  Turkmenistan                3.0   \n",
       "2      South Scott    OK    Luxembourg                3.0   \n",
       "3       Robinhaven    PR        Uganda                4.0   \n",
       "4      New Heather    IL       Namibia                3.0   \n",
       "\n",
       "   Marital Status Change Risk Rating  \n",
       "0                      2         Low  \n",
       "1                      2      Medium  \n",
       "2                      2      Medium  \n",
       "3                      2      Medium  \n",
       "4                      1         Low  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"financial_risk_assessment.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf27b04bd0d348",
   "metadata": {},
   "source": [
    "\"Before training the model, it is essential to check for the presence of missing values, as they must be appropriately addressed to ensure accurate results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d37d903cc824b467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:56.246538Z",
     "start_time": "2025-04-06T14:19:56.214793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         0\n",
       "Gender                      0\n",
       "Education Level             0\n",
       "Marital Status              0\n",
       "Income                   2250\n",
       "Credit Score             2250\n",
       "Loan Amount              2250\n",
       "Loan Purpose                0\n",
       "Employment Status           0\n",
       "Years at Current Job        0\n",
       "Payment History             0\n",
       "Debt-to-Income Ratio        0\n",
       "Assets Value             2250\n",
       "Number of Dependents     2250\n",
       "City                        0\n",
       "State                       0\n",
       "Country                     0\n",
       "Previous Defaults        2250\n",
       "Marital Status Change       0\n",
       "Risk Rating                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191edcb2ae01c7b5",
   "metadata": {},
   "source": [
    "\"To address the missing data, we chose to impute the mean for numerical columns and the mode for categorical columns. Given that there are 2,250 missing values across 6 columns in a dataset of 15,000 records, removing rows with missing data would result in the loss of at least one-sixth of the dataset. Consequently, filling the missing values was seemed a more suitable approach.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed4800eb67330a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:56.638961Z",
     "start_time": "2025-04-06T14:19:56.533996Z"
    }
   },
   "outputs": [],
   "source": [
    "for (columnName,columnData) in df.items():\n",
    "    if columnData.dtype in ['float64', 'int64']:\n",
    "        df[columnName] = df[columnName].fillna(columnData.mean())\n",
    "    else:\n",
    "        df[columnName] = df[columnName].fillna(columnData.mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02da1d537490824",
   "metadata": {},
   "source": [
    "Due to the presence of numerous non-binary attributes and limited computational capacity, we are unable to include all of our attributes in the model. As a result, we need to focus on the most relevant features. Therefore, we decided to drop the least important columns based on our assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc24f6cb59824fb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:56.849435Z",
     "start_time": "2025-04-06T14:19:56.832944Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['City', 'State', 'Country', 'Marital Status Change'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b8707862ae518",
   "metadata": {},
   "source": [
    "In accordance with the principles of Decision Tree algorithms, we chose to create average values for certain columns and assign others to the closest category. The idea behind this decision is that some of our columns have an excessive number of unique values, which complicates the splitting process at each node. To address this issue, we decided to limit the maximum number of distinct values allowed in each column, thereby simplifying the model's decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12bf8809bb9735c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:57.035025Z",
     "start_time": "2025-04-06T14:19:56.995432Z"
    }
   },
   "outputs": [],
   "source": [
    "def bin_numerical_columns(df, num_bins=7):\n",
    "    \"\"\"\n",
    "    Bins numerical columns into 'num_bins' discrete categories.\n",
    "    Each numerical value is rounded to the nearest bin based on its range.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - num_bins (int): The number of bins to create for numerical columns.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): The DataFrame with binned numerical columns.\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        # Check if the column is numerical\n",
    "        if np.issubdtype(df[column].dtype, np.number):\n",
    "            # Create bins using np.linspace to get evenly spaced bins based on min and max values\n",
    "            min_val = df[column].min()\n",
    "            max_val = df[column].max()\n",
    "            bins = np.linspace(min_val, max_val, num_bins+1)\n",
    "\n",
    "            # Assign each value to the closest bin\n",
    "            df[column] = pd.cut(df[column], bins=bins, labels=np.arange(1, num_bins+1), include_lowest=True)\n",
    "\n",
    "    return df\n",
    "df = bin_numerical_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62a891f3e59481",
   "metadata": {},
   "source": [
    "Since we cannot use external labels, we need to generate our own labels for the data. To do this, we decided to create a custom function that assigns a unique integer to each distinct attribute value, starting from 0 up to n, where n represents the number of unique values in the column. Additionally, we print the key-value pairs of the mappings for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9fbaa9b54c97086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:57.223188Z",
     "start_time": "2025-04-06T14:19:57.123775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "COLUMN ENCODING MAPPINGS\n",
      "==================================================\n",
      "\n",
      "Column: Gender\n",
      "----------------------------------------\n",
      "  0 → Male\n",
      "  1 → Female\n",
      "  2 → Non-binary\n",
      "Total categories: 3\n",
      "\n",
      "Column: Education Level\n",
      "----------------------------------------\n",
      "  0 → PhD\n",
      "  1 → Bachelor's\n",
      "  2 → Master's\n",
      "  3 → High School\n",
      "Total categories: 4\n",
      "\n",
      "Column: Marital Status\n",
      "----------------------------------------\n",
      "  0 → Divorced\n",
      "  1 → Widowed\n",
      "  2 → Single\n",
      "  3 → Married\n",
      "Total categories: 4\n",
      "\n",
      "Column: Loan Purpose\n",
      "----------------------------------------\n",
      "  0 → Business\n",
      "  1 → Auto\n",
      "  2 → Home\n",
      "  3 → Personal\n",
      "Total categories: 4\n",
      "\n",
      "Column: Employment Status\n",
      "----------------------------------------\n",
      "  0 → Unemployed\n",
      "  1 → Employed\n",
      "  2 → Self-employed\n",
      "Total categories: 3\n",
      "\n",
      "Column: Payment History\n",
      "----------------------------------------\n",
      "  0 → Poor\n",
      "  1 → Fair\n",
      "  2 → Excellent\n",
      "  3 → Good\n",
      "Total categories: 4\n",
      "\n",
      "Column: Risk Rating\n",
      "----------------------------------------\n",
      "  0 → Low\n",
      "  1 → Medium\n",
      "  2 → High\n",
      "Total categories: 3\n"
     ]
    }
   ],
   "source": [
    "encoding_maps = {}\n",
    "def dynamic_encode(column):\n",
    "    encoding_map = {}\n",
    "    encoded_values = []\n",
    "    current_max = 0\n",
    "\n",
    "    for value in column:\n",
    "        if value not in encoding_map:\n",
    "            encoding_map[value] = current_max\n",
    "            current_max += 1\n",
    "        encoded_values.append(encoding_map[value])\n",
    "\n",
    "    return encoded_values, encoding_map\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        encoded_column, encoding_map = dynamic_encode(df[column])\n",
    "        df[column] = encoded_column\n",
    "        encoding_maps[column] = encoding_map\n",
    "print(\"=\"*50)\n",
    "print(\"COLUMN ENCODING MAPPINGS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for column_name, mapping in encoding_maps.items():\n",
    "    print(f\"\\nColumn: {column_name}\")\n",
    "    print(\"-\"*40)\n",
    "    for value, code in mapping.items():\n",
    "        print(f\"{code:>3} → {value}\")\n",
    "    print(f\"Total categories: {len(mapping)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7d7327b49f782",
   "metadata": {},
   "source": [
    "The data is split into 70% for training, 15% for validation, and 15% for testing with the help of sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ccd02949664d8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:57.343560Z",
     "start_time": "2025-04-06T14:19:57.316077Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9703aa46640548",
   "metadata": {},
   "source": [
    "## ID3 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79a2d73684aa0e",
   "metadata": {},
   "source": [
    "Before the ID3 algorithm is implemented, some helper functions are defined. The entropy function is used to calculate the entropy of the target column, which measures the uncertainty of the data. The info_gain function is used to calculate the information gain for a given feature, helping in the selection of the best feature to split on. By computing the entropy for each feature and selecting the one with the highest information gain, the most informative splits are made at each node of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e3e2567e045d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:57.438500Z",
     "start_time": "2025-04-06T14:19:57.425806Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    \"\"\"\n",
    "    Calculate entropy of a target column\n",
    "    \"\"\"\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy = -np.sum([(counts[i]/np.sum(counts)) * log2(counts[i]/np.sum(counts))\n",
    "                      for i in range(len(elements))])\n",
    "    return entropy\n",
    "\n",
    "def info_gain(data, feature, target_name):\n",
    "    \"\"\"\n",
    "    Calculate information gain for splitting on a feature\n",
    "    \"\"\"\n",
    "    total_entropy = entropy(data[target_name])\n",
    "\n",
    "    # Calculate weighted entropy\n",
    "    vals, counts = np.unique(data[feature], return_counts=True)\n",
    "    weighted_entropy = np.sum([(counts[i]/np.sum(counts)) *\n",
    "                             entropy(data.where(data[feature]==vals[i]).dropna()[target_name])\n",
    "                             for i in range(len(vals))])\n",
    "\n",
    "    return total_entropy - weighted_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56136acd8244ebd",
   "metadata": {},
   "source": [
    "### How ID3 Algorithm Works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141728631cfd528",
   "metadata": {},
   "source": [
    "#### 1. Stopping Conditions:\n",
    "The algorithm stops growing the tree under two conditions:\n",
    "- If all the instances in the current dataset belong to the same class (i.e., no diversity in the target label), the algorithm terminates and returns the class label of the majority.\n",
    "- If no features remain to split on or the maximum depth of the tree (`max_depth`) has been reached, the algorithm assigns the most frequent class in the current subset of data.\n",
    "\n",
    "#### 2. Feature Selection:\n",
    "At each node, the algorithm calculates the **information gain** for each feature using the entropy of the dataset and selects the feature with the highest information gain to split the data. This helps in finding the best feature that divides the data in a way that maximizes the homogeneity of the resulting subsets.\n",
    "\n",
    "#### 3. Tree Construction:\n",
    "The tree is constructed by recursively splitting the data at each node:\n",
    "- The feature with the highest information gain is selected for the split.\n",
    "- The dataset is partitioned based on the values of the selected feature.\n",
    "- This process continues recursively for each subset of the data, creating new nodes in the tree.\n",
    "- Each node represents a decision based on the selected feature, and the tree is grown until a stopping condition is met.\n",
    "\n",
    "#### 4. How the ID3 Algorithm Works:\n",
    "The implementation of the ID3 algorithm works as follows:\n",
    "1. **Stopping Conditions:** The algorithm checks if the dataset is homogeneous (all instances belong to the same class) or if there are no more features to split on. If either condition is met, the algorithm returns the majority class label.\n",
    "2. **Feature Selection:** The algorithm calculates the information gain for each feature and selects the feature with the highest gain to split the data.\n",
    "3. **Recursion:** The dataset is split based on the selected feature, and the process is repeated recursively on each subset. This creates branches in the tree, and the process continues until the stopping conditions are met.\n",
    "4. **Tree Construction:** The result is a decision tree where each node corresponds to a decision based on a feature, and each leaf node corresponds to a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be2c86702302200a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:57.533689Z",
     "start_time": "2025-04-06T14:19:57.518693Z"
    }
   },
   "outputs": [],
   "source": [
    "def id3(data, original_data, features, target_name, max_depth=None, current_depth=0):\n",
    "    \"\"\"\n",
    "    ID3 Algorithm implementation\n",
    "    \"\"\"\n",
    "    # Stopping conditions\n",
    "    if len(np.unique(data[target_name])) <= 1:\n",
    "        return np.unique(data[target_name])[0]\n",
    "\n",
    "    if len(features) == 0 or (max_depth is not None and current_depth == max_depth):\n",
    "        return np.unique(data[target_name])[np.argmax(np.unique(data[target_name], return_counts=True)[1])]\n",
    "\n",
    "    # Select best feature\n",
    "    gains = [info_gain(data, feature, target_name) for feature in features]\n",
    "    best_feature = features[np.argmax(gains)]\n",
    "\n",
    "    # Create tree structure\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    # Remove best feature from features\n",
    "    features = [f for f in features if f != best_feature]\n",
    "\n",
    "    # Grow tree recursively\n",
    "    for value in np.unique(data[best_feature]):\n",
    "        sub_data = data.where(data[best_feature] == value).dropna()\n",
    "\n",
    "        if len(sub_data) == 0:\n",
    "            tree[best_feature][value] = np.unique(original_data[target_name])[\n",
    "                np.argmax(np.unique(original_data[target_name], return_counts=True)[1])]\n",
    "        else:\n",
    "            tree[best_feature][value] = id3(sub_data, original_data, features,\n",
    "                                           target_name, max_depth, current_depth+1)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137e4fe43c6ed58",
   "metadata": {},
   "source": [
    "## Predict Function for ID3 Algorithm\n",
    "\n",
    "The `predict` function is used to make predictions on new, unseen data using the decision tree that was built by the ID3 algorithm. It traverses the tree based on the feature values of the given sample, starting from the root node and moving down through the tree until it reaches a leaf node with a class label.\n",
    "\n",
    "### How the `predict` Function Works:\n",
    "\n",
    "1. **Traversal through the Tree:**\n",
    "   The function starts by iterating over the keys (features) in the decision tree. Each feature corresponds to a decision point (node) in the tree.\n",
    "\n",
    "2. **Decision at Each Node:**\n",
    "   For each feature in the tree, the corresponding value from the input sample (`sample[feature]`) is checked. If the value exists in the current node’s dictionary, the tree moves to the next level, where the value corresponds to a new subtree.\n",
    "\n",
    "3. **Recursive Traversal:**\n",
    "   - If the subtree is a dictionary (indicating that the node is not a leaf), the function calls itself recursively to continue the search down the tree.\n",
    "   - If a leaf node (a class label) is reached, the function returns the predicted class label.\n",
    "\n",
    "### Purpose:\n",
    "This function enables the decision tree to make a prediction by following the path dictated by the feature values in the input sample, ultimately returning the predicted class label for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e70fecf52aa24b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:57.621120Z",
     "start_time": "2025-04-06T14:19:57.612808Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tree, sample):\n",
    "    \"\"\"\n",
    "    Predicts the class label for a single sample using the trained decision tree.\n",
    "\n",
    "    Args:\n",
    "        tree: The trained decision tree (nested dictionary structure)\n",
    "        sample: A single data instance (dictionary or pandas Series)\n",
    "\n",
    "    Returns:\n",
    "        Predicted class label or None for unseen feature values\n",
    "    \"\"\"\n",
    "    # Get the first/only feature in the current node\n",
    "    current_feature = next(iter(tree))\n",
    "\n",
    "    # Get the feature value from the sample\n",
    "    feature_value = sample[current_feature]\n",
    "\n",
    "    # Check if this value exists in our tree\n",
    "    if feature_value in tree[current_feature]:\n",
    "        subtree = tree[current_feature][feature_value]\n",
    "\n",
    "        # If we've reached a leaf node, return its value\n",
    "        if not isinstance(subtree, dict):\n",
    "            return subtree\n",
    "\n",
    "        # Otherwise continue recursively\n",
    "        return predict(subtree, sample)\n",
    "\n",
    "    # Handle unseen feature values\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d599588a346bbc",
   "metadata": {},
   "source": [
    "The decision tree is built using the ID3 algorithm, and predictions are made on the validation and test sets. The performance metrics, such as confusion matrices and accuracies, are then acquired to evaluate the model's effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85ec0abc3a088b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:21:16.841790Z",
     "start_time": "2025-04-06T14:19:57.740527Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Train the model on the training set\n",
    "decision_tree = id3(\n",
    "    data=pd.concat([X_train, y_train], axis=1),\n",
    "    original_data=pd.concat([X_train, y_train], axis=1),\n",
    "    features=list(X_train.columns),\n",
    "    target_name=y_train.name,\n",
    "    max_depth=4\n",
    ")\n",
    "\n",
    "# Function to predict on a DataFrame\n",
    "def predict_df(tree, X):\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        pred = predict(tree, X.iloc[i])\n",
    "        predictions.append(pred)\n",
    "    return predictions\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = predict_df(decision_tree, X_val)\n",
    "y_test_pred = predict_df(decision_tree, X_test)\n",
    "\n",
    "# Handle None predictions by replacing them with most common class\n",
    "most_common_class = y_train.mode()[0]\n",
    "y_val_pred = [p if p is not None else most_common_class for p in y_val_pred]\n",
    "y_test_pred = [p if p is not None else most_common_class for p in y_test_pred]\n",
    "\n",
    "# Plotting confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    labels = sorted(list(set(y_true) | set(y_pred)))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return cm, labels\n",
    "\n",
    "# Manual metric calculation\n",
    "def manual_metrics(cm, labels):\n",
    "    total = cm.sum()\n",
    "    correct = 0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        TP = cm[i][i]\n",
    "        FP = sum(cm[:, i]) - TP\n",
    "        FN = sum(cm[i, :]) - TP\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        correct += TP\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Precision per class:\")\n",
    "    for lbl, val in zip(labels, precisions):\n",
    "        print(f\"  {lbl}: {val:.4f}\")\n",
    "    print(\"Recall per class:\")\n",
    "    for lbl, val in zip(labels, recalls):\n",
    "        print(f\"  {lbl}: {val:.4f}\")\n",
    "    print(\"F1 Score per class:\")\n",
    "    for lbl, val in zip(labels, f1s):\n",
    "        print(f\"  {lbl}: {val:.4f}\")\n",
    "    print(\"Macro Averages:\")\n",
    "    print(f\"  Precision: {np.mean(precisions):.4f}\")\n",
    "    print(f\"  Recall:    {np.mean(recalls):.4f}\")\n",
    "    print(f\"  F1 Score:  {np.mean(f1s):.4f}\")\n",
    "\n",
    "# Test Set Evaluation\n",
    "print(\"Test Set Evaluation\")\n",
    "print(\"-\" * 50)\n",
    "cm_test, labels_test = plot_confusion_matrix(y_test, y_test_pred, \"Test Set Confusion Matrix\")\n",
    "manual_metrics(cm_test, labels_test)\n",
    "\n",
    "# Validation Set Evaluation\n",
    "print(\"\\nValidation Set Evaluation\")\n",
    "print(\"-\" * 50)\n",
    "cm_val, labels_val = plot_confusion_matrix(y_val, y_val_pred, \"Validation Set Confusion Matrix\")\n",
    "manual_metrics(cm_val, labels_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f58e5e431ce6c9",
   "metadata": {},
   "source": [
    "It has been observed that the model is experiencing an overfitting issue, with a tendency to predict most individuals as having a low (0) risk score. This bias is likely caused by the distribution of the dataset, which appears to be relatively balanced across the different risk classes. Prior to the preprocessing steps, such as column removal and the binning method, the model predominantly predicted all instances as belonging to the low-risk category. After implementing these operations, the dataset was adjusted in a way that enabled the model to predict a wider range of outcomes. However, despite these efforts, the model's performance still exhibits a significant skew towards predicting the low-risk class, as shown by the confusion matrices and classification reports.\n",
    "The performance metrics from both the test and validation sets highlight this issue. The test set results show an accuracy of 0.54, with a macro average precision of 0.34, recall of 0.34, and F1-score of 0.32. Similarly, the validation set results indicate an accuracy of 0.53, with macro averages of 0.35 for precision, 0.33 for recall, and 0.31 for F1-score. These metrics suggest that while the model is better than random guessing, it still struggles to effectively differentiate between the risk classes, particularly for the higher risk categories (1 and 2). The performance on these classes is notably poor, as evidenced by the low precision, recall, and F1-scores for these classes in both the test and validation reports.The performance metrics from both the test and validation sets reveal an overfitting issue. The model achieves an accuracy of around 0.54, but struggles to differentiate between higher risk categories, with low precision, recall, and F1-scores for classes 1 and 2. Despite preprocessing steps like feature reduction and dataset modification, the model still tends to predict low risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d102d52c486838",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679cffd749b4237",
   "metadata": {},
   "source": [
    "# Pruning Paths with Low Information Gain\n",
    "\n",
    "## 1. Information Gain Threshold:\n",
    "At each node, the information gain is calculated for each feature. If the information gain is lower than a specified threshold (`min_ig_threshold`), it indicates that the feature does not contribute significantly to distinguishing between classes. The tree will then consider pruning these branches, simplifying the model.\n",
    "\n",
    "## 2. Pruning Process:\n",
    "- **Path Selection:** The tree identifies the weakest branches based on information gain.\n",
    "- **Majority Class Assignment:** For each path that will be pruned, the algorithm assigns the most frequent class label within the subset of the data corresponding to that path. This results in a leaf node that simply predicts the majority class for that subset of data.\n",
    "- **Recursion:** The pruning process continues recursively down the tree, pruning paths that contribute the least to class differentiation.\n",
    "\n",
    "## 3. How the Pruning Algorithm Works:\n",
    "The pruning algorithm works as follows:\n",
    "1. **Identify Weak Paths:** The algorithm first identifies paths in the decision tree that have the lowest information gain. These paths are potential candidates for pruning.\n",
    "2. **Prune Paths:** Each selected path is pruned by replacing its branches with a majority class prediction based on the data subset that followed that path.\n",
    "3. **Evaluate the Impact on Performance:** After pruning each path, the tree is evaluated on a validation set to check for performance changes (using metrics like accuracy).\n",
    "4. **Stopping Condition:** The algorithm stops pruning when no further improvement is observed, or when all paths with low information gain have been pruned.\n",
    "\n",
    "## 4. Tree Construction After Pruning:\n",
    "- The pruned tree is smaller and simpler, with fewer branches. Each node now represents a more generalized decision, based on the most frequent class label for that subset.\n",
    "- The process of pruning continues recursively until no more low-information-gain branches remain or the performance of the tree is no longer improving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f474e9ed785ee51a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:21:31.173103Z",
     "start_time": "2025-04-06T14:21:16.928664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 weakest paths to prune:\n",
      "1. Previous Defaults (IG: 0.0013, Samples: 10500)\n",
      "2. Previous Defaults → 4 → Age (IG: 0.0034, Samples: 3353)\n",
      "3. Previous Defaults → 6 → Age (IG: 0.0053, Samples: 1769)\n",
      "4. Previous Defaults → 2 → Assets Value (IG: 0.0058, Samples: 1749)\n",
      "5. Previous Defaults → 1 → Income (IG: 0.0075, Samples: 1821)\n",
      "\n",
      "Initial validation accuracy: 0.5324\n",
      "\n",
      "Pruning path 1: Previous Defaults\n",
      "New accuracy: 0.5964 (Δ+0.0640)\n",
      "\n",
      "Pruning path 2: Previous Defaults → 4 → Age\n",
      "New accuracy: 0.5964 (Δ+0.0000)\n",
      "\n",
      "Pruning path 3: Previous Defaults → 6 → Age\n",
      "New accuracy: 0.5964 (Δ+0.0000)\n",
      "\n",
      "Pruning path 4: Previous Defaults → 2 → Assets Value\n",
      "New accuracy: 0.5964 (Δ+0.0000)\n",
      "\n",
      "Pruning path 5: Previous Defaults → 1 → Income\n",
      "New accuracy: 0.5964 (Δ+0.0000)\n",
      "\n",
      "Final Pruned Tree Performance:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5964\n",
      "Precision per class:\n",
      "  0: 0.5964\n",
      "  1: 0.0000\n",
      "  2: 0.0000\n",
      "Recall per class:\n",
      "  0: 1.0000\n",
      "  1: 0.0000\n",
      "  2: 0.0000\n",
      "F1 Score per class:\n",
      "  0: 0.7472\n",
      "  1: 0.0000\n",
      "  2: 0.0000\n",
      "Macro Averages:\n",
      "  Precision: 0.1988\n",
      "  Recall:    0.3333\n",
      "  F1 Score:  0.2491\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def get_weakest_twigs_with_ig(tree, X_train, y_train, target_name, top_n=5, print_output=True):\n",
    "    \"\"\"Analyze the tree and return the top-n weakest twigs based on Information Gain\"\"\"\n",
    "    full_data = pd.concat([X_train, y_train], axis=1)\n",
    "    node_info = []\n",
    "\n",
    "    def traverse(node, path=[]):\n",
    "        if isinstance(node, dict):\n",
    "            for feature, branches in node.items():\n",
    "                subset = full_data.copy()\n",
    "                for f, v in zip(path[::2], path[1::2]):\n",
    "                    subset = subset[subset[f] == v]\n",
    "\n",
    "                if subset.empty:\n",
    "                    continue\n",
    "\n",
    "                current_ig = info_gain(subset, feature, target_name)\n",
    "                class_dist = subset[target_name].value_counts(normalize=True).to_dict()\n",
    "\n",
    "                node_info.append({\n",
    "                    'path': path + [feature],\n",
    "                    'ig': current_ig,\n",
    "                    'class_dist': class_dist,\n",
    "                    'n_samples': len(subset)\n",
    "                })\n",
    "\n",
    "                for value, subtree in branches.items():\n",
    "                    traverse(subtree, path + [feature, value])\n",
    "\n",
    "    traverse(tree)\n",
    "\n",
    "    node_report = pd.DataFrame(node_info).sort_values('ig').reset_index(drop=True)\n",
    "\n",
    "    if print_output:\n",
    "        print(f\"\\nTop {top_n} weakest paths to prune:\")\n",
    "        for i, row in node_report.head(top_n).iterrows():\n",
    "            print(f\"{i+1}. {' → '.join(map(str, row['path']))} (IG: {row['ig']:.4f}, Samples: {row['n_samples']})\")\n",
    "\n",
    "    return node_report.head(top_n)['path'].tolist()\n",
    "\n",
    "\n",
    "def prune_paths_by_majority_class(tree, paths_to_prune, X_train, y_train, X_val, y_val, target_name):\n",
    "    \"\"\"Prune given paths and evaluate performance after each pruning\"\"\"\n",
    "    current_tree = copy.deepcopy(tree)\n",
    "    majority_class = y_train.mode()[0]\n",
    "\n",
    "    # Helper: prune specific path\n",
    "    def prune_path(tree, path):\n",
    "        node = tree\n",
    "        for step in path[:-1]:\n",
    "            if isinstance(node, dict):\n",
    "                node = node.get(step, {})\n",
    "            else:\n",
    "                return  # Early leaf reached\n",
    "\n",
    "        last_feature = path[-1]\n",
    "        subset = pd.concat([X_train, y_train], axis=1)\n",
    "        for feature, value in zip(path[::2], path[1::2]):\n",
    "            subset = subset[subset[feature] == value]\n",
    "\n",
    "        majority = subset[target_name].mode()[0] if not subset.empty else majority_class\n",
    "\n",
    "        if isinstance(node, dict) and last_feature in node:\n",
    "            for val in node[last_feature]:\n",
    "                node[last_feature][val] = majority\n",
    "\n",
    "    # Function to calculate accuracy manually\n",
    "    def manual_accuracy(y_true, y_pred):\n",
    "        correct = 0\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            if true == pred:\n",
    "                correct += 1\n",
    "        return correct / len(y_true) if len(y_true) > 0 else 0\n",
    "\n",
    "    # Initial evaluation\n",
    "    y_val_pred = predict_df(current_tree, X_val)\n",
    "    y_val_pred = [pred if pred is not None else majority_class for pred in y_val_pred]\n",
    "    last_acc = manual_accuracy(y_val, y_val_pred)\n",
    "    print(f\"\\nInitial validation accuracy: {last_acc:.4f}\")\n",
    "\n",
    "    for i, path in enumerate(paths_to_prune, 1):\n",
    "        print(f\"\\nPruning path {i}: {' → '.join(map(str, path))}\")\n",
    "        prune_path(current_tree, path)\n",
    "\n",
    "        y_val_pred = predict_df(current_tree, X_val)\n",
    "        y_val_pred = [pred if pred is not None else majority_class for pred in y_val_pred]\n",
    "        current_acc = manual_accuracy(y_val, y_val_pred)\n",
    "        print(f\"New accuracy: {current_acc:.4f} (Δ{current_acc - last_acc:+.4f})\")\n",
    "        last_acc = current_acc\n",
    "\n",
    "    return current_tree\n",
    "\n",
    "\n",
    "# Step 1: Get weakest twigs\n",
    "weakest_paths = get_weakest_twigs_with_ig(decision_tree, X_train, y_train, y_train.name, top_n=5)\n",
    "\n",
    "# Step 2: Prune and evaluate\n",
    "pruned_tree = prune_paths_by_majority_class(\n",
    "    decision_tree,\n",
    "    weakest_paths,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    y_train.name\n",
    ")\n",
    "\n",
    "# Final performance after pruning\n",
    "print(\"\\nFinal Pruned Tree Performance:\")\n",
    "y_val_pred = predict_df(pruned_tree, X_val)\n",
    "\n",
    "# Replace None predictions with the most common class\n",
    "y_val_pred = [p if p is not None else most_common_class for p in y_val_pred]\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_pruned, labels_pruned = plot_confusion_matrix(\n",
    "    y_val, y_val_pred,\n",
    "    \"Validation Set Confusion Matrix On Pruned Tree\"\n",
    ")\n",
    "\n",
    "# Calculate and print manual metrics instead of using classification_report\n",
    "manual_metrics(cm_pruned, labels_pruned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ff35a97f386bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T14:21:31.194469Z",
     "start_time": "2025-04-06T14:21:31.191115Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
